# -*- coding: utf-8 -*-
"""Deepfake_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fm9D90j4rjpJAEy88p_FRIdLHWVOnB1O
"""

#Optical flow field generation using Farneback method
import cv2 as cv
import numpy as np
import os
from skimage.transform import resize

def get_optical_flow(file,frame_limit,matrix_shape):
    cap = cv.VideoCapture(file)
    # ret = a boolean return value from getting the frame, first_frame = the first frame in the entire video sequence
    ret, first_frame = cap.read()
    # Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive
    prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)
    
    #set how many frames to take from each video
    #frame_limit = 40
    frame_count = 0
    #matrix_shape = 200

    flows2= np.zeros((frame_limit,matrix_shape,matrix_shape,2))
    while(cap.isOpened()):
        
        # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video
        ret, frame = cap.read()
       
        # Converts each frame to grayscale - we previously only converted the first frame to grayscale
        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
        
        # Calculates dense optical flow by Farneback method
        flow = cv.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)
        
        #Computes the magnitude and angle of the 2D vectors
        magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])
        
        #Resize each matrix to be matrix_shape
        magnitude_reduced = resize(magnitude,(matrix_shape,matrix_shape))
        angle_reduced = resize(angle,(matrix_shape,matrix_shape))
        
        
        #stack the magnitude and angle matrices into a 3d array
        flow_tensor = np.dstack((magnitude_reduced,angle_reduced))
        
        #add each 3d array to list of 3d arrays for each frame
        flows2[frame_count] = flow_tensor
        
        # Updates previous frame
        prev_gray = gray
        frame_count +=1
        # Program stops calculating optical flow when frame limit is reached
        if frame_count == frame_limit:
            break
    # The following frees up resources
    cap.release()
    
    flows2 = np.array(flows2)
    return flows2

#Optical flow field generation for rgb optical flows

import cv2 as cv
import numpy as np
import os
from skimage.transform import resize

def get_optical_flow(file,frame_limit,matrix_shape):
    cap = cv.VideoCapture(file)
    # ret = a boolean return value from getting the frame, first_frame = the first frame in the entire video sequence
    ret, first_frame = cap.read()
    # Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive
    prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)
    # Creates an image filled with zero intensities with the same dimensions as the frame
    mask = np.zeros_like(first_frame)
    # Sets image saturation to maximum
    mask[..., 1] = 255
   
    frame_count = 0

    flows= np.zeros((frame_limit,matrix_shape,matrix_shape,3))
    
    while(frame_count<frame_limit):
        
        # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video
        ret, frame = cap.read()
       
        # Converts each frame to grayscale - we previously only converted the first frame to grayscale
        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
        
        # Calculates dense optical flow by Farneback method
        flow = cv.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)
        
        #Computes the magnitude and angle of the 2D vectors
        magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])
        
        # Sets image hue according to the optical flow direction
        mask[..., 0] = angle * 180 / np.pi / 2
        
        # Sets image value according to the optical flow magnitude (normalized)
        mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)
      
        # Converts HSV to RGB (BGR) color representation
        rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)
        rgb = resize(rgb, (matrix_shape,matrix_shape))
             
        #add each 3d array to list of 3d arrays for each frame
        flows[frame_count] = rgb
        
        # Updates previous frame
        prev_gray = gray
        frame_count +=1

    # The following frees up resources
    cap.release()
    
    flows = np.array(flows)
    return flows

#Optical flow field generation for fourier transform

import cv2 as cv
import numpy as np
import os
from skimage.transform import resize

def get_optical_flow(file,frame_limit,matrix_shape):
    cap = cv.VideoCapture(file)
    # ret = a boolean return value from getting the frame, first_frame = the first frame in the entire video sequence
    ret, first_frame = cap.read()
    # Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive
    prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)
    # Creates an image filled with zero intensities with the same dimensions as the frame
    mask = np.zeros_like(first_frame)
    # Sets image saturation to maximum
    mask[..., 1] = 255
   
    frame_count = 0

    flows= np.zeros((frame_limit,matrix_shape,matrix_shape,3))
    
    while(frame_count<frame_limit):
        
        # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video
        ret, frame = cap.read()
       
        # Converts each frame to grayscale - we previously only converted the first frame to grayscale
        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
        
        # Calculates dense optical flow by Farneback method
        flow = cv.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)
        
        #Computes the magnitude and angle of the 2D vectors
        magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])
        
        # Sets image hue according to the optical flow direction
        mask[..., 0] = angle * 180 / np.pi / 2
        
        # Sets image value according to the optical flow magnitude (normalized)
        mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)
      
        # Converts HSV to RGB (BGR) color representation
        rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)
        rgb = resize(rgb, (matrix_shape,matrix_shape))

        # fourier transform
        dft = np.fft.fft2(rgb)
        dft = np.fft.fftshift(dft)
        data = np.log(1+np.abs(dft))     
        #add each 3d array to list of 3d arrays for each frame
        flows[frame_count] = data
        
        # Updates previous frame
        prev_gray = gray
        frame_count +=1

    # The following frees up resources
    cap.release()
    
    flows = np.array(flows)
    return flows

#get optical flow rgb face function
import cv2 as cv
import numpy as np
from google.colab.patches import cv2_imshow
import os

def get_optical_flow(file, frame_limit, matrix_shape):
    
    face_cascade = cv.CascadeClassifier('/content/drive/My Drive/MAE 496/Data/face detection/haarcascade_frontalface_default.xml')
    cap = cv.VideoCapture(file)

    # ret = a boolean return value from getting the frame, first_frame = the first frame in the entire video sequence
    ret, first_frame = cap.read()
    # Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive

    prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)

    first_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)

    mask = np.zeros_like(first_frame)
    mask[..., 1] = 255
    
    frame_count = 0

    flows2= np.zeros((frame_limit,matrix_shape,matrix_shape,3))

    while(cap.isOpened()):
      # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video
        ret, frame = cap.read()
       
        # Converts each frame to grayscale - we previously only converted the first frame to grayscale
        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
        
        try:
          face_cascade.detectMultiScale(gray, 1.1, 4)[0]
          face = face_cascade.detectMultiScale(gray, 1.1, 4)
          for (x, y, w, h) in face:
            startX = int(x)
            endX = int(x + w)
            startY = int(y*1.1)
            endY = int((y + h)*1.1)
        except:
          print('no face detected')
          startX = 0
          startY = 0 
          endX = np.shape(gray)[1]
          endY = np.shape(gray)[0]
        
        # Calculates dense optical flow by Farneback method
        flow = cv.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)
        
        #flow_face = flow[startY:endY,startX:endX]  
        #flow_face = cv.resize(flow_face,(matrix_shape,matrix_shape))  

        # Computes the magnitude and angle of the 2D vectors
        magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])

        # Sets image value according to the optical flow magnitude (normalized)
        mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)

        # Sets image hue according to the optical flow direction
        mask[..., 0] = angle * 180 / np.pi / 2

        # Converts HSV to RGB (BGR) color representation
        rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)
        rgb_face = rgb[startY:endY,startX:endX]
        
        try:
          rgb_face = cv.resize(rgb_face,(matrix_shape,matrix_shape))
        except:
          print('error resizing')
          rgb_face = flows2[frame_count-1]

        flows2[frame_count] = rgb_face
        cv2_imshow(rgb_face)

        # Updates previous frame and face
        prev_gray = gray
        frame_count +=1
        # Program stops calculating optical flow when frame limit is reached
        if frame_count == frame_limit:
            break

    # The following frees up resources
    cap.release()
    
    flows2 = np.array(flows2)
    return flows2

#get optical field over face function
import cv2 as cv
import numpy as np

def get_optical_flow(file, frame_limit, matrix_shape):

    face_cascade = cv.CascadeClassifier('/content/drive/My Drive/MAE 496/Data/face detection/haarcascade_frontalface_default.xml')
    cap = cv.VideoCapture(file)

    # ret = a boolean return value from getting the frame, first_frame = the first frame in the entire video sequence
    ret, first_frame = cap.read()
    # Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive
    prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)
    
    frame_count = 0

    flows2= np.zeros((frame_limit,matrix_shape,matrix_shape,2))

    while(cap.isOpened()):
        
        # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video
        ret, frame = cap.read()
       
        # Converts each frame to grayscale - we previously only converted the first frame to grayscale
        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)

        try:
          face_cascade.detectMultiScale(gray, 1.1, 4)[0]
          face = face_cascade.detectMultiScale(gray, 1.1, 4)
          for (x, y, w, h) in face:
            startX = int(x)
            endX = int(x + w)
            startY = int(y*.9)
            endY = int((y + h)*1.1)
        except:
          print('no face detected')
          startX = 0
          startY = 0 
          endX = np.shape(gray)[1]
          endY = np.shape(gray)[0]
        
        # Calculates dense optical flow by Farneback method
        flow = cv.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)
        
        flow_face = flow[startY:endY,startX:endX]  
        try:
          flow_face = cv.resize(flow_face,(matrix_shape,matrix_shape))
        except:
          print('error resizing')        
          flow_face = flows2[0]
        
        #add each 3d array to list of 3d arrays for each frame
        flows2[frame_count] = flow_face
        
        # Updates previous frame
        #prev_gray = gray
        frame_count +=1
        # Program stops calculating optical flow when frame limit is reached
        if frame_count == frame_limit:
            break
    
    # The following frees up resources
    cap.release()
    
    flows2 = np.array(flows2)
    return flows2

def count_files(file_path):
  import os
  catalogs = os.walk(file_path)
  count = 0
  for root, _, files in catalogs:
      if root[-1] == 'o':
        for name in files:
          count +=1
      if root[-1] == 's':
        for name in files:
          count +=1
  return count

#count  = count_files('/content/drive/My Drive/MAE 496/Data/FaceForensics/train/s')
#print(count)

#function to generate optical flows for every video in a folder (improved)
import os

def get_data2(file_path,frame_limit,matrix_shape,channels):

    file_count = count_files(file_path)
    catalogs = os.walk(file_path)
    samples = np.zeros((file_count,frame_limit,matrix_shape,matrix_shape,channels))
    labels = np.zeros(file_count)
    count = 0
    

    for root, _, files in catalogs:
        #  get the original videos
        if root[-1] == 'o':
            for name in files:
                vid_path = os.path.join(root, name)
             
                samples[count] = (get_optical_flow(vid_path,frame_limit,matrix_shape))
                labels[count] = 0
                count+=1
                print(count)
              
        #  get the swapped videos
        if root[-1] == 's':
            for name in files:
                vid_path = os.path.join(root, name)
                
                samples[count] = (get_optical_flow(vid_path,frame_limit,matrix_shape))
                labels[count] = 1
                count+=1
                print(count)

    return samples, labels

#generate flow fields and real/fake labels for each video 
x1, y1 = get_data2('/content/drive/My Drive/MAE 496/Data/set2',40,100,2)

#save generated test sample and label data to local files
#import numpy as np
np.save('/content/drive/My Drive/MAE 496/Data/optical flows/x2_df_face_frame1',x1)
np.save('/content/drive/My Drive/MAE 496/Data/optical flows/y2_df_face_frame1',y1)

np.save('/content/drive/My Drive/MAE 496/Data/Fourier/x2_fourier',x2)
np.save('/content/drive/My Drive/MAE 496/Data/Fourier/y2_fourier',y2)

#Load 1st half train Data ff
import numpy as np
x1 = np.load('/content/drive/My Drive/MAE 496/Data/optical flows/x1_df_face_frame1.npy')
y1 = np.load('/content/drive/My Drive/MAE 496/Data/optical flows/y1_df_face_frame1.npy')

#Load 2nd half train data fourier
import numpy as np
x2 = np.load('/content/drive/My Drive/MAE 496/Data/optical flows/x2_df_face_frame1.npy')
y2 = np.load('/content/drive/My Drive/MAE 496/Data/optical flows/y2_df_face_frame1.npy')

#Combine half data sets and save
x12 = np.concatenate((x1,x2))
y12 = np.concatenate((y1,y2))

np.save('/content/drive/My Drive/MAE 496/Data/optical flows/x12_df_face_frame1.npy',x12)
np.save('/content/drive/My Drive/MAE 496/Data/optical flows/y12_df_face_frame1.npy',y12)

#load full training labels
import numpy as np
y1 = np.load('/content/drive/My Drive/MAE 496/Data/optical flows/y12_df_face_frame1.npy')

#load full training optical flows
x1 = np.load('/content/drive/My Drive/MAE 496/Data/optical flows/x12_df_face_frame1.npy')

#Function to create convolutional lstm model 

import tensorflow 
from tensorflow.keras.layers import ConvLSTM2D, Dense, Dropout, MaxPooling3D, MaxPooling2D, Flatten, BatchNormalization
from tensorflow.keras import Input
from tensorflow.keras.models import Model
from random import shuffle

#create complex model
def complex_ConvLSTM_Model(frames, pixels_x, pixels_y, channels):
   
    flow_input =  Input(shape=(frames, pixels_x, pixels_y, channels)
                    , name='flow_input')
    
    first_lstm = ConvLSTM2D(filters=20, kernel_size=(3, 3)
                       , recurrent_activation='hard_sigmoid'
                       , activation='tanh'
                       , padding='same', 
                       return_sequences=True)
    
    second_lstm  = ConvLSTM2D(filters=10, kernel_size=(3, 3)
                        , padding='same', 
                        return_sequences=True)
    
    third_lstm = ConvLSTM2D(filters=5, kernel_size=(3, 3)
                        , stateful = False
                        , kernel_initializer='random_uniform'
                        , padding='same')
    
    lstm1 = first_lstm(flow_input)
    batch1 = BatchNormalization()(lstm1)
    pool1 = MaxPooling3D(pool_size=(2, 2, 1), padding='same', data_format='channels_first')(batch1)
    lstm2 = second_lstm(pool1)
    batch2 = BatchNormalization()(lstm2)
    pool2 = MaxPooling3D(pool_size=(2,2, 1), padding='same', data_format='channels_first')(batch2)
    lstm3 = third_lstm(pool2)
    pool3 = MaxPooling2D(pool_size=(2, 2), padding='same')(lstm3)
    flat = Flatten()(pool3)
    dense = Dense(512,)(flat)
    dropout = Dropout(0.5)(dense)
    output_layer = Dense(1, activation = 'sigmoid')(dropout)
    
    model = Model(inputs = flow_input, outputs = output_layer)
    return model

#create model with variable nodes

import tensorflow 
from tensorflow.keras.layers import ConvLSTM2D, Dense, Dropout, MaxPooling3D, MaxPooling2D, Flatten, BatchNormalization
from tensorflow.keras import Input
from tensorflow.keras.models import Model
from random import shuffle

def complex_ConvLSTM_Model2(frames, pixels_x, pixels_y, channels,nodes):
   
    flow_input =  Input(shape=(frames, pixels_x, pixels_y, channels)
                    , name='flow_input')
    
    first_lstm = ConvLSTM2D(filters=20, kernel_size=(3, 3)
                       , recurrent_activation='hard_sigmoid'
                       , activation='tanh'
                       , padding='same', 
                       return_sequences=True)
    
    second_lstm  = ConvLSTM2D(filters=10, kernel_size=(3, 3)
                        , padding='same', 
                        return_sequences=True)
    
    third_lstm = ConvLSTM2D(filters=5, kernel_size=(3, 3)
                        , stateful = False
                        , kernel_initializer='random_uniform'
                        , padding='same')
    
    lstm1 = first_lstm(flow_input)
    batch1 = BatchNormalization()(lstm1)
    pool1 = MaxPooling3D(pool_size=(2, 2, 1), padding='same', data_format='channels_first')(batch1)
    lstm2 = second_lstm(pool1)
    batch2 = BatchNormalization()(lstm2)
    pool2 = MaxPooling3D(pool_size=(3,3, 1), padding='same', data_format='channels_first')(batch2)
    lstm3 = third_lstm(pool2)
    pool3 = MaxPooling2D(pool_size=(2, 2), padding='same')(lstm3)
    flat = Flatten()(pool3)
    dense = Dense(nodes,)(flat)
    dropout = Dropout(0.5)(dense)
    output_layer = Dense(1, activation = 'sigmoid')(dropout)
    
    model = Model(inputs = flow_input, outputs = output_layer)
    return model

#Function to create convolutional lstm model 

import tensorflow 
from tensorflow.keras.layers import ConvLSTM2D, Dense, Dropout, MaxPooling3D, MaxPooling2D, Flatten, BatchNormalization
from tensorflow.keras import Input
from tensorflow.keras.models import Model
from random import shuffle

#create complex model
def complex_ConvLSTM_Model(frames, pixels_x, pixels_y, channels):
   
    flow_input =  Input(shape=(frames, pixels_x, pixels_y, channels)
                    , name='flow_input')
    
    first_lstm = ConvLSTM2D(filters=20, kernel_size=(3, 3)
                       , recurrent_activation='hard_sigmoid'
                       , activation='tanh'
                       , padding='same', 
                       return_sequences=True)
    
    second_lstm  = ConvLSTM2D(filters=5, kernel_size=(3, 3)
                        , stateful = False
                        , kernel_initializer='random_uniform'
                        , padding='same' 
                        )
    
    third_lstm = ConvLSTM2D(filters=5, kernel_size=(3, 3)
                        , stateful = False
                        , kernel_initializer='random_uniform'
                        , padding='same')
    
    lstm1 = first_lstm(flow_input)
    batch1 = BatchNormalization()(lstm1)
    pool1 = MaxPooling3D(pool_size=(2, 2, 1), padding='same', data_format='channels_first')(batch1)
    lstm2 = second_lstm(pool1)
    batch2 = BatchNormalization()(lstm2)
    pool2 = MaxPooling2D(pool_size=(3,3), padding='same')(batch2)
    #lstm3 = third_lstm(pool2)
    #pool3 = MaxPooling2D(pool_size=(2, 2), padding='same')(lstm3)
    flat = Flatten()(pool2)
    dense = Dense(512,)(flat)
    dropout = Dropout(0.5)(dense)
    output_layer = Dense(1, activation = 'sigmoid')(dropout)
    
    model = Model(inputs = flow_input, outputs = output_layer)
    return model

model.summary()

#compile model
from tensorflow.keras.optimizers import Adam

model = complex_ConvLSTM_Model(40, 100, 100, 2)
optimizer = Adam(lr=0.0001)
model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy'])

#generate model plot
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.vis_utils import plot_model
#model.summary()
plot_model(model, to_file='model2_plot.png', show_shapes=True, show_layer_names=True)

#create generator to load training data and use less RAM
from random import shuffle
def generator(ids,samples,labels):
    while True:
        shuffle(ids)
        for i in ids:
            x = samples[i]
            label = labels[i]
            yield(np.array([x]),np.array([label]))

# create generator with batches
batch_size = 10
def generator(ids,x,y, batch_size = batch_size):
  while True:
# Select files (paths/indices) for the batch
          batch_paths  = np.random.choice(a  = ids, size = batch_size)
          batch_input  = []
          batch_output = [] 

          for i in batch_paths:
            x_val = x[i]
            y_val = y[i]
            batch_input += [ x_val ]
            batch_output += [ y_val ]

          batch_x = np.array( batch_input )
          batch_y = np.array( batch_output )
        
          yield( batch_x, batch_y )

#create training and testing data
from sklearn.model_selection import train_test_split
from random import shuffle

available_ids = list(range(len(x1)))

shuffle(available_ids)

train_ids,test_ids = train_test_split(available_ids,train_size = 0.8)

test_ids

#train the model with generator with early stopping
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.callbacks import ModelCheckpoint
import os

path = '/content/drive/My Drive/MAE 496/models/model9 (df first frame)'
mc_acc = ModelCheckpoint(os.path.join(path,'bestAcc_model9.h5'), monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)
mc_loss = ModelCheckpoint(os.path.join(path,'bestLoss_model9.h5'), monitor='val_loss', mode='min', verbose=1, save_best_only=True)
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience =8)

history = model.fit_generator(
    generator(train_ids,x1,y1)
    , steps_per_epoch = len(train_ids)/batch_size
  
    , validation_data = generator(test_ids,x1,y1)
    , validation_steps = len(test_ids)/batch_size
  
    , epochs = 50
    , verbose = 1
    , callbacks=[es, mc_acc, mc_loss]
    , initial_epoch = 0
    )

#saving the model
import h5py

model.save(os.path.join(path,"model9.h5"))
print("Saved model to disk")

#saving training history
import pandas as pd
hist_df = pd.DataFrame(history.history) 

# save to json:  
hist_json_file = os.path.join(path,'history_model9.json') 
with open(hist_json_file, mode='w') as f:
    hist_df.to_json(f)
print("Saved model history")

#model training with grid search
from sklearn.model_selection import ParameterGrid
#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
path = '/content/drive/My Drive/MAE 496/models/model3'
es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience =5)

# define the grid search parameters
learn_rate = [ 0.0001]
momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]
nodes = [350,400,450,512]
param_grid = dict(nodes=nodes)
best_score = 0
count = 0

for g in ParameterGrid(param_grid):
  print(g)
  model = complex_ConvLSTM_Model2(40, 200, 200, 2,g['nodes'])
  optimizer = Adam(lr=0.0001)
  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
  
  history = model.fit_generator(
    generator(train_ids,x1,y1)
    , steps_per_epoch = len(train_ids)/batch_size
  
    , validation_data = generator(test_ids,x1,y1)
    , validation_steps = len(test_ids)/batch_size
  
    , epochs = 40
    , verbose = 1
    , callbacks=[es]
    , initial_epoch = 0
    )
  
  #get model accuracy
  acc = list(history.history['val_accuracy'])[-1]
  
  #update best model accuracy and save
  if acc > best_score:
    best_score = acc
    best_grid = g
    print("best_score: %.5f" %best_score)
    print("best_grid: ", best_grid)

    #saving model
    import h5py
    import os
    model.save(os.path.join(path,"model3.h5"))
    
    #saving training history
    import pandas as pd
    hist_df = pd.DataFrame(history.history)
    # save to json:  
    hist_json_file = os.path.join(path,'history_model3.json') 
    with open(hist_json_file, mode='w') as f:
        hist_df.to_json(f)
    
print("best_score: %.5f" %best_score)
print("best_grid: ", best_grid)

#loading training histories

import pandas as pd
import json

with open('/content/drive/My Drive/MAE 496/models/model2/history1_model2.json') as f:
  history1 = json.load(f)

with open('/content/drive/My Drive/MAE 496/models/model2/history2_model2.json') as g:
  history2 = json.load(g)

with open('/content/drive/My Drive/MAE 496/models/model2/history3_model2.json') as h:
  history3 = json.load(h)

with open('/content/drive/My Drive/MAE 496/models/model2/history4_model2.json') as i:
  history4 = json.load(i)

list(history.history['val_accuracy'])[-1]

#combining all training accuracies

train_acc = []
val_acc = []


for i in history1['val_acc']:
  val_acc.append(history1['val_acc'][i])

for i in history1['acc']:
  train_acc.append(history1['val_acc'][i])

for i in history2['val_acc']:
  val_acc.append(history2['val_acc'][i])

for i in history2['acc']:
  train_acc.append(history2['acc'][i])

for i in history3['val_acc']:
  val_acc.append(history3['val_acc'][i])

for i in history3['acc']:
  train_acc.append(history3['acc'][i])

for i in history4['val_acc']:
  val_acc.append(history4['val_acc'][i])
  
for i in history4['acc']:
  train_acc.append(history4['acc'][i])

#combining all training losses
train_loss = []
val_loss = []


for i in history1['val_loss']:
  val_loss.append(history1['val_loss'][i])

for i in history1['loss']:
  train_loss.append(history1['loss'][i])

for i in history2['loss']:
  val_loss.append(history2['loss'][i])

for i in history2['acc']:
  train_loss.append(history2['acc'][i])

for i in history3['val_loss']:
  val_loss.append(history3['val_loss'][i])

for i in history3['loss']:
  train_loss.append(history3['loss'][i])

for i in history4['val_loss']:
  val_loss.append(history4['val_loss'][i])
  
for i in history4['loss']:
  train_loss.append(history4['loss'][i])

#plotting model accuracy
import matplotlib.pyplot as plt

plt.plot(train_acc)
plt.plot(val_acc)
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Training', 'Validation'], loc='upper left')
plt.show()

#saving accuracies
np.save('/content/drive/My Drive/MAE 496/models/model2/trainAcc1-4_model2',train_acc)
np.save('/content/drive/My Drive/MAE 496/models/model2/valAcc1-4_model2',val_acc)

#plotting losses
import matplotlib.pyplot as plt

plt.plot(train_loss)
plt.plot(val_loss)
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Training', 'Validation'], loc='upper left')
plt.show()

#saving losses
np.save('/content/drive/My Drive/MAE 496/models/model2/trainLoss1-4_model2',train_loss)
np.save('/content/drive/My Drive/MAE 496/models/model2/valLoss1-4_model2',val_loss)

# summarize history for accuracy
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# importing saved JSON model later...
from tensorflow.keras.models import model_from_json
import h5py

# load json and create model
json_file = open('/content/drive/My Drive/MAE 496/models/model2/model2_4.json', 'r')
trained_model = json_file.read()
json_file.close()
model = model_from_json(trained_model)
# load weights into new model
model.load_weights('/content/drive/My Drive/MAE 496/models/model2/model2_4.h5')
print("Loaded model from disk")
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#importing saved keras model
from tensorflow.keras.models import load_model
model_acc = load_model('/content/drive/My Drive/MAE 496/models/model3/bestAcc_model3.h5')
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#printing model metrics
print(model.metrics_names)

import numpy as np
samples = np.load('/content/drive/My Drive/MAE 496/Data/face2face set/x1_f2f.npy')
labels = np.load('/content/drive/My Drive/MAE 496/Data/face2face set/y1_f2f.npy')

#model evaluation
available_ids = list(range(len(samples)))
loss, acc = model.evaluate(generator(available_ids,samples,labels,batch_size),steps =len(samples)/batch_size)

#model evaluation
available_ids = list(range(len(x1)))
loss, acc = model.evaluate(generator(available_ids,x1,y1,batch_size),steps =len(x1)/batch_size)